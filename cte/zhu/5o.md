Nice — this is a long one, so I’ll answer each sub-part (a)–(j) clearly and compactly. I’ll include short diagrams (ASCII), truth/excitation tables where needed, worked values for conversions and IEEE-754 encodings, and explanations of how circuits operate.

---

## (a) Harvard architecture (with diagram) and storage of data & instructions

**Definition:** Harvard architecture uses physically separate memories (and typically separate buses) for instructions and data. This allows simultaneous access to program code and data, giving higher throughput for instruction fetch and data access.

**Block diagram (simplified ASCII):**

```
   CPU
  ┌──────┐
  │ ALU  │
  └─┬────┘
    │    ▲
    │    │
    ▼    │
+--------+   +-----------------+
| Instr  |<--| Instruction Bus |<-- Instruction Memory (ROM/Flash)
|  Unit  |   +-----------------+
| (PC)   |
+---┬----+
    │
    │           +----------------+
    ▼           |   Data Memory  |<-- Data Bus (RAM)
+-------+       +----------------+
| Regs  |
+-------+
```

**How stored:**

* **Instructions** are stored in instruction memory (often ROM/Flash) at instruction addresses; fetched via the instruction bus into the instruction unit / PC.
* **Data** are stored in a separate data memory (RAM). CPU uses data bus / load-store instructions to read/write data memory. Because memories are separate, instruction fetch and data access can happen simultaneously (e.g., load while fetching next instruction).

**Advantages:** parallel instruction & data access, simpler instruction word fetch timing (no instruction/data contention).
**Disadvantages:** increased hardware cost/complexity, data/instruction transfer between spaces requires explicit mechanisms.

---

## (b) How the CPU executes `int a=25, b=75, c; c = b - a;`

**High-level steps a simple compiler + CPU perform (conceptual):**

1. **Compile-time / linkage:** allocate storage for variables `a`, `b`, `c` in memory or registers (say memory addresses `addr_a`, `addr_b`, `addr_c`).
2. **Initialization:** load constant 25 into memory/register for `a`; load 75 into `b`.

   * e.g., machine ops:

     * `MOV R0, #25` ; `STORE R0 -> addr_a`
     * `MOV R1, #75` ; `STORE R1 -> addr_b`
3. **Execute `c = b - a;`**

   * **Fetch** instruction `SUB R2, addr_b, addr_a` or `LOAD R0, addr_b` ; `LOAD R1, addr_a` ; `SUB R2, R0, R1` ; `STORE R2 -> addr_c`.
   * **ALU operation:** ALU computes `75 - 25 = 50`, result placed in target register or memory.
4. **Write-back:** store result `50` into `c`’s memory location or keep in register mapped to `c`.

**Micro-operation sequence example (load/store CPU):**

* `LOAD R0, addr_b`  ; R0 ← 75
* `LOAD R1, addr_a`  ; R1 ← 25
* `SUB R2, R0, R1`   ; R2 ← R0 − R1 = 50
* `STORE R2, addr_c` ; memory[addr_c] ← 50

---

## (c) Number conversions

### (i) Decimal → Binary & Hex

**(9567438120)_{10} → binary & hexadecimal**

* Binary (base-2): `1000 1110 1001 0000 1110 0001 0100 1010 00`
  (without spaces) **`1000111010010000111000010100101000`**
* Hex (base-16): **`23A438528`** (uppercase)

> *(computed by repeated division/computer-aided conversion — shown result above)*

---

### (ii) Hexadecimal → Binary & Octal

**(8FAEB1DC)_{16}**

* Binary (32-bit grouping): **`10001111101011101011000111011100`**
* Octal (base-8): **`21753530734`**

(Each hex digit → 4 bits; group binary to octal by 3-bit groups.)

---

### (iii) ASCII string `"ABCabc$#4325 & Unicode"` → UTF-8 bytes

UTF-8 for plain ASCII characters is the same as ASCII code (1 byte per char). Hexadecimal byte sequence:

`41 42 43 61 62 63 24 23 34 33 32 35 20 26 20 55 6E 69 63 6F 64 65`

(That is: `A B C a b c $ # 4 3 2 5 <space> & <space> U n i c o d e` — 22 bytes total.)

---

### (iv) Octal → Decimal

**(41302576)_{8} → decimal**

Compute: `41302576_8 = 8^6*4 + 8^5*1 + 8^4*3 + 8^3*0 + 8^2*2 + 8^1*7 + 8^0*6`
Value = **8,750,462** (decimal).

---

## (d) K-map simplification & NAND-only circuit

Given: (F(A,B,C,D) = \Sigma(0,2,4,6,8,10,15)).

**Step (K-map grouping) result (simplified SOP):**
[
F = D' (A' + B') + A B C D
]
Equivalent expanded:
[
F = A' D' + B' D' + A B C D
]

**Explanation:** The six minterms with D=0 (0,2,4,6,8,10) cover all ABC combinations except where A=B=1; so for D=0 output is true unless A=B=1 → (D' ( \overline{A B} ) = D'(A' + B')). The minterm 15 (1111) adds (A B C D).

**NAND-only implementation (how to implement using NANDs):**

1. Implement `A' D'` and `B' D'` and `A B C D` and then OR them. Using NAND gates:

   * For `A' D'`:

     * NAND1 = NAND(A, A) → produces A' (inverter)
     * NAND2 = NAND(D, D) → produces D'
     * NAND3 = NAND(NAND1_out, NAND2_out) → NAND of (A',D') gives (A'·D')'
     * then NAND again to invert: NAND4 = NAND(NAND3_out, NAND3_out) → gives A'·D'
   * Alternatively implement the OR `A'D' + B'D' + ABCD` via De Morgan as NAND of NANDs:

     * Compute X = A'·D' (as above), Y = B'·D', Z = A·B·C·D (use NAND chain producing (A·B·C·D)' then invert appropriate way), then final Yout = OR(X,Y,Z) = NAND( NAND(X,X), NAND(Y,Y), NAND(Z,Z) ) with only NAND gates (use multi-input NAND realized as cascaded NANDs).
       (You can synthesize exact gate netlist by replacing every inversion/OR with standard NAND gate patterns.)

---

## (e) Adder-Subtractor: perform A − B with A = `0011`, B = `1101`  (4-bit)

**Given:** A = 0011 (3), B = 1101 (13). Want A − B.

**Method (two’s complement subtraction):** compute A + (two’s complement of B). Two’s complement of B = bitwise NOT(B) + 1.

* B = `1101`
* NOT(B) = `0010`
* NOT(B)+1 = `0011` (this equals 3)

**Add A + (~B + 1):**

```
   A   = 0 0 1 1
   ~B+1= 0 0 1 1
---------------- (add bitwise LSB to MSB)
 bit0: 1 + 1 = 0, carry 1
 bit1: 1 + 1 + carry1 = 1, carry 1
 bit2: 0 + 0 + carry1 = 1, carry 0
 bit3: 0 + 0 + carry0 = 0, carry 0
Result = 0 1 1 0  (0110)
Final carry out (Cout) = 0
```

**Bitwise table (LSB -> MSB):**

* Bit0: A0=1, B0'(+1)0=1, Sum0=0, Carry0→1
* Bit1: A1=1, B1'(+1)1=1, Sum1=1, Carry→1
* Bit2: A2=0, B2'(+1)2=0, Sum2=1, Carry→0
* Bit3: A3=0, B3'(+1)3=0, Sum3=0, Carry→0

**Result in 4-bit two’s complement:** `0110` which is decimal +6.
**Interpretation:** A − B = 3 − 13 = −10. In 4-bit two’s complement, −10 ≡ 6 (mod 16), so the 4-bit pattern `0110` is the arithmetic result modulo 16.
**Overflow?** Overflow test for two’s complement addition = (carry into MSB) XOR (carry out of MSB). Here carry-in-to-MSB = 0 and carry-out = 0 → overflow = 0 (no overflow).

---

## (f) 4×1 Multiplexer — truth table, logic diagram & example

**Truth table** (Inputs: I0..I3, Select S1 S0):

| S1 | S0 | Y  |
| -- | -- | -- |
| 0  | 0  | I0 |
| 0  | 1  | I1 |
| 1  | 0  | I2 |
| 1  | 1  | I3 |

**Logic expression:**
[
Y = \overline{S1},\overline{S0},I_0 + \overline{S1},S0,I_1 + S1,\overline{S0},I_2 + S1,S0,I_3
]

**Logic diagram (conceptual):**

* Four 3-input AND gates:

  * AND1 = NOT(S1) AND NOT(S0) AND I0
  * AND2 = NOT(S1) AND S0 AND I1
  * AND3 = S1 AND NOT(S0) AND I2
  * AND4 = S1 AND S0 AND I3
* One OR gate to combine AND1..AND4 → Y

**Example:** If S1=0, S0=1 then Y = I1 (the mux routes input I1 to output).

---

## (g) Hamming code (single-error detect & correct) — example

**Given:** source 4-bit data = `1111`. It was received as `0111` (i.e., one data bit flipped). Use Hamming(7,4).

**Hamming(7,4) layout:** bit positions 1..7:
1 = p1, 2 = p2, 3 = d3, 4 = p4, 5 = d2, 6 = d1, 7 = d0.
Let data bits (d3,d2,d1,d0) = 1,1,1,1.

**Compute parity bits (even parity):**

* p1 covers positions 1,3,5,7 → p1 = d3⊕d2⊕d0 = 1⊕1⊕1 = 1
* p2 covers positions 2,3,6,7 → p2 = d3⊕d1⊕d0 = 1⊕1⊕1 = 1
* p4 covers positions 4,5,6,7 → p4 = d2⊕d1⊕d0 = 1⊕1⊕1 = 1

**Transmitted codeword:** `p1 p2 d3 p4 d2 d1 d0` = `1 1 1 1 1 1 1` → `1111111`.

**Error scenario:** suppose d3 flips from 1→0 during transmission; received codeword = `1 1 0 1 1 1 1` (`1101111`).

**Syndrome bits (parity checks):**

* s1 = p1 ⊕ d3 ⊕ d2 ⊕ d0 = 1⊕0⊕1⊕1 = 1
* s2 = p2 ⊕ d3 ⊕ d1 ⊕ d0 = 1⊕0⊕1⊕1 = 1
* s4 = p4 ⊕ d2 ⊕ d1 ⊕ d0 = 1⊕1⊕1⊕1 = 0
  Syndrome (s4 s2 s1) = `011` = decimal **3** ⇒ error at position 3.

**Correction:** flip bit 3 (0→1); corrected codeword → `1111111` → data recovered `1111`.

Thus Hamming detects error position 3 and corrects it.

---

## (h) JK flip-flop: functioning, characteristic table & excitation table

**JK flip-flop**: edge-triggered flip-flop where inputs are J and K and output Q. It overcomes invalid state of SR by toggling when both inputs =1.

**Characteristic equation:**
[
Q_{next} = J\overline{Q} + \overline{K} Q
]

**Characteristic table** (present Q, inputs J K → next Q):

| J | K | Q_next        |
| - | - | ------------- |
| 0 | 0 | Q (no change) |
| 0 | 1 | 0 (reset)     |
| 1 | 0 | 1 (set)       |
| 1 | 1 | Q' (toggle)   |

**Excitation table** (given present Q and required Q_next, what J,K needed):

| Q | Q_next | J | K |
| - | ------ | - | - |
| 0 | 0      | 0 | X |
| 0 | 1      | 1 | X |
| 1 | 0      | X | 1 |
| 1 | 1      | X | 0 |

(Where X = don't care.)

**Logic diagram (concept):** master latch and slave latch with feedback to implement JK functionality; typical implementation uses gated SR latches + feedback from Q and Q' to drive S and R inputs when J,K asserted. (Textbook diagrams show J feeding gate to set and K to reset through gating network and feedback.)

---

## (i) Master-Slave flip-flop — functioning

**Structure:** two level latching: a **master latch** and a **slave latch**. When clock (CLK) = 1 (for positive-level master), master is transparent and captures input; when CLK falls to 0, master closes and slave opens, so slave takes master's value. For an edge-triggered master-slave, output changes on clock edge.

**Operation:**

* On rising edge (or appropriate edge depending on design), the master samples inputs while slave holds previous state. When the clock transitions, master closes (freezes), slave opens and follows master's output → thus output updates only at clock transitions → edge triggered behavior and avoids race conditions.

(Diagram: two latches in series, controlled by complementary clock phases.)

---

## (j) IEEE-754 single precision representations

IEEE-754 single precision = 32 bits: 1 sign bit | 8 exponent bits (bias 127) | 23 fraction bits (mantissa without leading 1).

### (i) Represent ((-126.5)_{10})

* Sign = 1 (negative)
* Absolute value = 126.5 = `1111110.1`₂ (since 126 = `1111110`, .5 = .1)
* Normalize: `1.1111101 × 2^6` (because shift point left 6 positions)
* Exponent = 6 → exponent field = 6 + 127 = 133 → `10000101` (binary)
* Mantissa (fraction) = bits after leading 1: `1111101` followed by zeros to fill 23 bits → `11111010000000000000000` (23 bits)

**32-bit pattern (sign|exp|mantissa):**
`1 10000101 11111010000000000000000`

Binary: **`11000010111111010000000000000000`**
Hex: **`C2FD0000`**

*(Matches the IEEE-754 canonical encoding.)*

---

### (ii) Represent (0.015625_{10})

* 0.015625 = 1/64 = (2^{-6}).
* Binary normalized: `1.0 × 2^{-6}` → leading 1, exponent = −6 → exponent field = −6 + 127 = 121 → `01111001` (binary)
* Mantissa = fractional part after leading 1 is 0 → all zeros.

**32-bit pattern:**
`0 01111001 00000000000000000000000`

Binary: **`00111100100000000000000000000000`**
Hex: **`3C800000`**

---

## Final notes

* I kept the answers compact but complete for each sub-question.
* If you want, I can:

  * produce neat printable diagrams (PNG/SVG) for the circuits,
  * give a step-by-step long division conversion for (c)(i) to show manual decimal→binary conversion, or
  * convert the simplified K-map expression into an explicit NAND-only netlist with gate counts.

Which of those (if any) would you like next?

